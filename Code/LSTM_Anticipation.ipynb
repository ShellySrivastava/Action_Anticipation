{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLSTM_Anticipation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tczGg3ZoBnn",
        "colab_type": "text"
      },
      "source": [
        "Acticipate Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkP9JhtKoSav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ActicipateDataset(Dataset):\n",
        "\n",
        "    def __init__(self, is_batch = True):\n",
        "\n",
        "        self.is_batch = is_batch\n",
        "        self.head_positions = np.load('/content/drive/My Drive/head_key_points.npy')\n",
        "        self.body_positions = np.load('/content/drive/My Drive/body_key_points.npy')\n",
        "        self.ball_positions = np.load('/content/drive/My Drive/ball_key_points.npy')\n",
        "        self.frame_info = np.load('/content/drive/My Drive/frame_info.npy')\n",
        "        self.data_labels = np.load(\"/content/drive/My Drive/action_labels.npy\")[:,1]\n",
        "        # change the label of action class 12 to 0 for compatibility with cross entropy loss \n",
        "        self.data_labels[self.data_labels == 12] = 0\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.frame_info.shape[0]\n",
        "\n",
        "    def __getitem__(self, id):\n",
        "        first, last = int(self.frame_info[id][0]), int(self.frame_info[id][1])+1\n",
        "        if self.is_batch == True:\n",
        "            if last >= first + 100:\n",
        "                last = first + 100\n",
        "                return self.head_positions[first:last], self.body_positions[first:last], self.ball_positions[first:last], self.data_labels[first:last]\n",
        "            else: \n",
        "                pad = first + 100 - last\n",
        "                return np.concatenate((self.head_positions[first:last], np.zeros((pad,12))), axis = 0), np.concatenate((self.body_positions[first:last], np.zeros((pad,12))), axis = 0), np.concatenate((self.ball_positions[first:last], np.zeros((pad,2))), axis = 0), np.concatenate((self.data_labels[first:last], np.ones((pad))*100), axis = 0)\n",
        "        else:\n",
        "            return self.head_positions[first:last], self.body_positions[first:last], self.ball_positions[first:last], self.data_labels[first:last]\n",
        "\n",
        "# Acticipate dataset is called with set batch to False\n",
        "# this means the sequences will not be truncated or padded to fit a batch\n",
        "# the data loader has to run with a batch_size of 1\n",
        "dataset = ActicipateDataset(False)\n",
        "train_size = int(0.8 * dataset.__len__())\n",
        "val_size = int(0.1 * dataset.__len__())\n",
        "test_size = dataset.__len__() - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yBYJbMxiDPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvSVutqtoFJJ",
        "colab_type": "text"
      },
      "source": [
        "To get the source embedding as described in the paper Santos et al. (2019)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FozbY5tiGKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class get_embedding(nn.Module):\n",
        "    def __init__(self, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input2emb_body = nn.Linear(12,16)\n",
        "        self.input2emb_head = nn.Linear(12,16)\n",
        "        self.input2emb_ball = nn.Linear(2,16)\n",
        "        self.input2emb_context = nn.Linear(32,16)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, in_head, in_body, in_ball):\n",
        "\n",
        "        in_head = self.input2emb_head(in_head.float())\n",
        "        in_body = self.input2emb_body(in_body.float())\n",
        "        in_ball = self.input2emb_ball(in_ball.float())\n",
        "        in_context = self.input2emb_context(torch.cat((in_head, in_ball), 1))\n",
        "        embedding = torch.cat((in_body, in_context), 1)\n",
        "\n",
        "        embedded = self.dropout(embedding)\n",
        "      \n",
        "        return embedded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC84CPEfoUVz",
        "colab_type": "text"
      },
      "source": [
        "Get the deterministic LSTM model as described in Santos et al. (2019)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iDcoWmTiM70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_model(nn.Module):\n",
        "    def __init__(self, emb_dim, hid_dim, out_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.input2emb = nn.Linear(32, emb_dim)\n",
        "        self.rnn1 = nn.LSTM(emb_dim, hid_dim, batch_first = True )\n",
        "        self.rnn2 = nn.LSTM(emb_dim, hid_dim, batch_first = True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc_out = nn.Linear(hid_dim, out_dim)\n",
        "\n",
        "    def forward(self, embedded, h1, c1, h2, c2):\n",
        "\n",
        "        embedded = self.dropout(self.input2emb(embedded))\n",
        "        embedded.unsqueeze_(1)\n",
        "        output, (h1, c1) = self.rnn1(embedded, (h1, c1))\n",
        "        h1.permute(1,0,2)\n",
        "        output, (h2, c2) = self.rnn2(h1, (h2, c2))\n",
        "        prediction = self.fc_out(h2.squeeze(0))\n",
        "        return prediction, h1, c1, h2, c2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qiL2XKvoaLF",
        "colab_type": "text"
      },
      "source": [
        "Acticipate model to train the embeddings and LSTM model together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5BuQFGQiPlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Anticipate_model(nn.Module):\n",
        "      def __init__(self, embedding, lstm_model):\n",
        "          super().__init__()\n",
        "          \n",
        "          self.embedding = embedding\n",
        "          self.lstm_model = lstm_model\n",
        "          self.hid_dim = self.lstm_model.hid_dim\n",
        "          self.out_dim = self.lstm_model.out_dim\n",
        "\n",
        "      def forward(self, inputs):\n",
        "          head, body, ball = inputs\n",
        "          batch_size = head.shape[0]\n",
        "          seq_len = head.shape[1]\n",
        "          outputs = torch.zeros(batch_size, seq_len, self.out_dim).cuda()\n",
        "          h1 = torch.zeros(1, batch_size, self.hid_dim).cuda()\n",
        "          c1 = torch.zeros(1, batch_size, self.hid_dim).cuda()\n",
        "          h2 = torch.zeros(1, batch_size, self.hid_dim).cuda()\n",
        "          c2 = torch.zeros(1, batch_size, self.hid_dim).cuda()\n",
        "          for i in range(seq_len):\n",
        "              embs = self.embedding(head[:,i,:], body[:,i,:], ball[:,i,:])\n",
        "              pred, h1, c1, h2, c2 = self.lstm_model(embs, h1,c1, h2, c2)\n",
        "              outputs[:,i,:] = pred\n",
        "          return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9DtV5ErogE0",
        "colab_type": "text"
      },
      "source": [
        "Initialise the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTXOblsniR4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = get_embedding(0.5).cuda()\n",
        "lstm = LSTM_model(64, 64, 12, 0.5).cuda()\n",
        "model = Anticipate_model(embedding, lstm).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zni9Ez93ohmU",
        "colab_type": "text"
      },
      "source": [
        "Initialise the adam optimiser and LR scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BQgPlSJiT1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min', verbose=True, patience=5, factor = 0.1)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7LC4G68om1i",
        "colab_type": "text"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnQDv3PkiWxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "\n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        head, body, ball, trg = batch\n",
        "        head = head.cuda()\n",
        "        body = body.cuda()\n",
        "        ball = ball.cuda()\n",
        "      \n",
        "        trg = trg.long().cuda()\n",
        "        input_embs = (head, body, ball)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(input_embs)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output.view(-1, output_dim)\n",
        "        trg = trg.view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ79e64boveb",
        "colab_type": "text"
      },
      "source": [
        "Evaluation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLkvH7IxiaVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            head, body, ball, trg = batch\n",
        "            head = head.cuda()\n",
        "            body = body.cuda()\n",
        "            ball = ball.cuda()\n",
        "\n",
        "            trg = trg.long().cuda()\n",
        "            input_embs = (head, body, ball)\n",
        "            output = model(input_embs) \n",
        "\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.view(-1, output_dim)\n",
        "            trg = trg.view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5gy606cic3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uShi2UN5o3JF",
        "colab_type": "text"
      },
      "source": [
        "Run the cell to train the model for the given epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtbVncBQifSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb269b9d-fbc6-4331-e840-59aeb389fd83"
      },
      "source": [
        "N_EPOCHS = 60\n",
        "CLIP = 0.1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, val_loader, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    lr_scheduler.step(valid_loss)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/DLSTM_best_val_final.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/DLSTM_epoch_end_final.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 35s\n",
            "\tTrain Loss: 2.488\n",
            "\t Val. Loss: 2.600\n",
            "Epoch: 02 | Time: 0m 35s\n",
            "\tTrain Loss: 2.471\n",
            "\t Val. Loss: 2.443\n",
            "Epoch: 03 | Time: 0m 35s\n",
            "\tTrain Loss: 2.372\n",
            "\t Val. Loss: 2.178\n",
            "Epoch: 04 | Time: 0m 35s\n",
            "\tTrain Loss: 2.268\n",
            "\t Val. Loss: 2.266\n",
            "Epoch: 05 | Time: 0m 35s\n",
            "\tTrain Loss: 2.126\n",
            "\t Val. Loss: 1.952\n",
            "Epoch: 06 | Time: 0m 35s\n",
            "\tTrain Loss: 2.016\n",
            "\t Val. Loss: 1.556\n",
            "Epoch: 07 | Time: 0m 35s\n",
            "\tTrain Loss: 1.691\n",
            "\t Val. Loss: 1.603\n",
            "Epoch: 08 | Time: 0m 35s\n",
            "\tTrain Loss: 1.583\n",
            "\t Val. Loss: 2.071\n",
            "Epoch: 09 | Time: 0m 35s\n",
            "\tTrain Loss: 1.776\n",
            "\t Val. Loss: 1.635\n",
            "Epoch: 10 | Time: 0m 35s\n",
            "\tTrain Loss: 1.632\n",
            "\t Val. Loss: 1.485\n",
            "Epoch: 11 | Time: 0m 35s\n",
            "\tTrain Loss: 1.527\n",
            "\t Val. Loss: 1.241\n",
            "Epoch: 12 | Time: 0m 35s\n",
            "\tTrain Loss: 1.504\n",
            "\t Val. Loss: 1.245\n",
            "Epoch: 13 | Time: 0m 35s\n",
            "\tTrain Loss: 1.304\n",
            "\t Val. Loss: 1.558\n",
            "Epoch: 14 | Time: 0m 35s\n",
            "\tTrain Loss: 1.351\n",
            "\t Val. Loss: 0.899\n",
            "Epoch: 15 | Time: 0m 35s\n",
            "\tTrain Loss: 1.227\n",
            "\t Val. Loss: 1.030\n",
            "Epoch: 16 | Time: 0m 35s\n",
            "\tTrain Loss: 1.107\n",
            "\t Val. Loss: 0.679\n",
            "Epoch: 17 | Time: 0m 35s\n",
            "\tTrain Loss: 1.297\n",
            "\t Val. Loss: 1.314\n",
            "Epoch: 18 | Time: 0m 35s\n",
            "\tTrain Loss: 1.200\n",
            "\t Val. Loss: 1.078\n",
            "Epoch: 19 | Time: 0m 35s\n",
            "\tTrain Loss: 0.976\n",
            "\t Val. Loss: 0.624\n",
            "Epoch: 20 | Time: 0m 35s\n",
            "\tTrain Loss: 1.243\n",
            "\t Val. Loss: 1.019\n",
            "Epoch: 21 | Time: 0m 35s\n",
            "\tTrain Loss: 1.035\n",
            "\t Val. Loss: 0.585\n",
            "Epoch: 22 | Time: 0m 35s\n",
            "\tTrain Loss: 1.011\n",
            "\t Val. Loss: 0.539\n",
            "Epoch: 23 | Time: 0m 35s\n",
            "\tTrain Loss: 0.880\n",
            "\t Val. Loss: 0.658\n",
            "Epoch: 24 | Time: 0m 35s\n",
            "\tTrain Loss: 0.913\n",
            "\t Val. Loss: 0.764\n",
            "Epoch: 25 | Time: 0m 35s\n",
            "\tTrain Loss: 0.841\n",
            "\t Val. Loss: 0.668\n",
            "Epoch: 26 | Time: 0m 35s\n",
            "\tTrain Loss: 1.040\n",
            "\t Val. Loss: 0.467\n",
            "Epoch: 27 | Time: 0m 35s\n",
            "\tTrain Loss: 0.822\n",
            "\t Val. Loss: 0.496\n",
            "Epoch: 28 | Time: 0m 35s\n",
            "\tTrain Loss: 0.835\n",
            "\t Val. Loss: 0.682\n",
            "Epoch: 29 | Time: 0m 34s\n",
            "\tTrain Loss: 0.910\n",
            "\t Val. Loss: 0.528\n",
            "Epoch: 30 | Time: 0m 34s\n",
            "\tTrain Loss: 0.882\n",
            "\t Val. Loss: 0.398\n",
            "Epoch: 31 | Time: 0m 34s\n",
            "\tTrain Loss: 0.846\n",
            "\t Val. Loss: 0.411\n",
            "Epoch: 32 | Time: 0m 34s\n",
            "\tTrain Loss: 0.869\n",
            "\t Val. Loss: 0.556\n",
            "Epoch: 33 | Time: 0m 34s\n",
            "\tTrain Loss: 0.806\n",
            "\t Val. Loss: 0.897\n",
            "Epoch: 34 | Time: 0m 34s\n",
            "\tTrain Loss: 0.838\n",
            "\t Val. Loss: 0.404\n",
            "Epoch: 35 | Time: 0m 34s\n",
            "\tTrain Loss: 0.776\n",
            "\t Val. Loss: 0.406\n",
            "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch: 36 | Time: 0m 34s\n",
            "\tTrain Loss: 0.783\n",
            "\t Val. Loss: 0.418\n",
            "Epoch: 37 | Time: 0m 34s\n",
            "\tTrain Loss: 0.832\n",
            "\t Val. Loss: 0.372\n",
            "Epoch: 38 | Time: 0m 34s\n",
            "\tTrain Loss: 0.711\n",
            "\t Val. Loss: 0.482\n",
            "Epoch: 39 | Time: 0m 34s\n",
            "\tTrain Loss: 0.735\n",
            "\t Val. Loss: 0.420\n",
            "Epoch: 40 | Time: 0m 34s\n",
            "\tTrain Loss: 0.740\n",
            "\t Val. Loss: 0.412\n",
            "Epoch: 41 | Time: 0m 34s\n",
            "\tTrain Loss: 0.737\n",
            "\t Val. Loss: 0.391\n",
            "Epoch: 42 | Time: 0m 34s\n",
            "\tTrain Loss: 0.633\n",
            "\t Val. Loss: 0.390\n",
            "Epoch    43: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch: 43 | Time: 0m 34s\n",
            "\tTrain Loss: 0.637\n",
            "\t Val. Loss: 0.389\n",
            "Epoch: 44 | Time: 0m 34s\n",
            "\tTrain Loss: 0.647\n",
            "\t Val. Loss: 0.389\n",
            "Epoch: 45 | Time: 0m 34s\n",
            "\tTrain Loss: 0.611\n",
            "\t Val. Loss: 0.388\n",
            "Epoch: 46 | Time: 0m 34s\n",
            "\tTrain Loss: 0.589\n",
            "\t Val. Loss: 0.387\n",
            "Epoch: 47 | Time: 0m 34s\n",
            "\tTrain Loss: 0.697\n",
            "\t Val. Loss: 0.386\n",
            "Epoch: 48 | Time: 0m 34s\n",
            "\tTrain Loss: 0.653\n",
            "\t Val. Loss: 0.387\n",
            "Epoch    49: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch: 49 | Time: 0m 34s\n",
            "\tTrain Loss: 0.643\n",
            "\t Val. Loss: 0.387\n",
            "Epoch: 50 | Time: 0m 34s\n",
            "\tTrain Loss: 0.607\n",
            "\t Val. Loss: 0.387\n",
            "Epoch: 51 | Time: 0m 34s\n",
            "\tTrain Loss: 0.601\n",
            "\t Val. Loss: 0.387\n",
            "Epoch: 52 | Time: 0m 34s\n",
            "\tTrain Loss: 0.624\n",
            "\t Val. Loss: 0.387\n",
            "Epoch: 53 | Time: 0m 34s\n",
            "\tTrain Loss: 0.643\n",
            "\t Val. Loss: 0.387\n",
            "Epoch: 54 | Time: 0m 34s\n",
            "\tTrain Loss: 0.557\n",
            "\t Val. Loss: 0.387\n",
            "Epoch    55: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch: 55 | Time: 0m 34s\n",
            "\tTrain Loss: 0.596\n",
            "\t Val. Loss: 0.386\n",
            "Epoch: 56 | Time: 0m 34s\n",
            "\tTrain Loss: 0.582\n",
            "\t Val. Loss: 0.386\n",
            "Epoch: 57 | Time: 0m 34s\n",
            "\tTrain Loss: 0.635\n",
            "\t Val. Loss: 0.386\n",
            "Epoch: 58 | Time: 0m 34s\n",
            "\tTrain Loss: 0.609\n",
            "\t Val. Loss: 0.386\n",
            "Epoch: 59 | Time: 0m 34s\n",
            "\tTrain Loss: 0.618\n",
            "\t Val. Loss: 0.386\n",
            "Epoch: 60 | Time: 0m 34s\n",
            "\tTrain Loss: 0.554\n",
            "\t Val. Loss: 0.386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M_2CNYRo9WB",
        "colab_type": "text"
      },
      "source": [
        "Load the model weights to reproduce the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scmWSVvzQqfF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "237e822c-258a-4958-ceb7-7a8629bafc28"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/My Drive/DLSTM_epoch_end_final.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq7I54-dpyI7",
        "colab_type": "text"
      },
      "source": [
        "Function to get the prediction using the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAyQ4gb6xELd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_predictions(head,body,ball, model, device, max_len = 100):\n",
        "\n",
        "    model.eval()\n",
        "    body_tensor = torch.from_numpy(body)\n",
        "    body_tensor = body_tensor.unsqueeze(0).cuda()\n",
        "    head_tensor = torch.from_numpy(head)\n",
        "    head_tensor = head_tensor.unsqueeze(0).cuda()\n",
        "    ball_tensor = torch.from_numpy(ball)\n",
        "    ball_tensor = ball_tensor.unsqueeze(0).cuda()\n",
        "    batch_size = 1\n",
        "    seq_len = ball.shape[0]\n",
        "    predictions = []\n",
        "    h1 = torch.zeros(1, batch_size, model.hid_dim).cuda()\n",
        "    c1 = torch.zeros(1, batch_size, model.hid_dim).cuda()\n",
        "    h2 = torch.zeros(1, batch_size, model.hid_dim).cuda()\n",
        "    c2 = torch.zeros(1, batch_size, model.hid_dim).cuda()\n",
        "    m = nn.Softmax(dim=1)\n",
        "    for i in range(seq_len):\n",
        "        embs = model.embedding(head_tensor[:,i,:], body_tensor[:,i,:], ball_tensor[:,i,:])\n",
        "        pred, h1, c1, h2, c2 = model.lstm_model(embs, h1,c1, h2, c2)\n",
        "        val, action_class = torch.max(m(pred), dim=1)\n",
        "        if val.item() > 0.9:\n",
        "            predictions.append(action_class)\n",
        "        else:\n",
        "            predictions.append(-1)\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4cpYHzJprs5",
        "colab_type": "text"
      },
      "source": [
        "Run the cell to get accuracy at each observation ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fubSGRDLxG_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e568e4e0-a21b-4f9a-f37f-358901003f54"
      },
      "source": [
        "accuracy = []\n",
        "ratios = []\n",
        "for i in range(1,101):\n",
        "  count = 0\n",
        "  ratio = i/100\n",
        "  for k in range(dataset.__len__()):\n",
        "    head, body,ball, trg = dataset.__getitem__(k)\n",
        "    action_len = len(trg)\n",
        "    last = int(action_len * ratio) + 1\n",
        "    output = get_predictions(head[0:last],body[0:last],ball[0:last], model, None)\n",
        "    if output[-1] == trg[0]:\n",
        "      count = count+1\n",
        "  acc = count/dataset.__len__()\n",
        "  accuracy.append(acc)\n",
        "  ratios.append(ratio)\n",
        "  print('Observation ratio: '+str(ratio)+' and Accuracy: '+str(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation ratio: 0.01 and Accuracy: 0.3375\n",
            "Observation ratio: 0.02 and Accuracy: 0.3541666666666667\n",
            "Observation ratio: 0.03 and Accuracy: 0.3625\n",
            "Observation ratio: 0.04 and Accuracy: 0.375\n",
            "Observation ratio: 0.05 and Accuracy: 0.3875\n",
            "Observation ratio: 0.06 and Accuracy: 0.3958333333333333\n",
            "Observation ratio: 0.07 and Accuracy: 0.4041666666666667\n",
            "Observation ratio: 0.08 and Accuracy: 0.4\n",
            "Observation ratio: 0.09 and Accuracy: 0.4125\n",
            "Observation ratio: 0.1 and Accuracy: 0.4166666666666667\n",
            "Observation ratio: 0.11 and Accuracy: 0.43333333333333335\n",
            "Observation ratio: 0.12 and Accuracy: 0.44166666666666665\n",
            "Observation ratio: 0.13 and Accuracy: 0.44583333333333336\n",
            "Observation ratio: 0.14 and Accuracy: 0.45416666666666666\n",
            "Observation ratio: 0.15 and Accuracy: 0.45\n",
            "Observation ratio: 0.16 and Accuracy: 0.45416666666666666\n",
            "Observation ratio: 0.17 and Accuracy: 0.4666666666666667\n",
            "Observation ratio: 0.18 and Accuracy: 0.4708333333333333\n",
            "Observation ratio: 0.19 and Accuracy: 0.475\n",
            "Observation ratio: 0.2 and Accuracy: 0.4791666666666667\n",
            "Observation ratio: 0.21 and Accuracy: 0.4791666666666667\n",
            "Observation ratio: 0.22 and Accuracy: 0.48333333333333334\n",
            "Observation ratio: 0.23 and Accuracy: 0.4875\n",
            "Observation ratio: 0.24 and Accuracy: 0.4875\n",
            "Observation ratio: 0.25 and Accuracy: 0.4875\n",
            "Observation ratio: 0.26 and Accuracy: 0.4875\n",
            "Observation ratio: 0.27 and Accuracy: 0.5\n",
            "Observation ratio: 0.28 and Accuracy: 0.5041666666666667\n",
            "Observation ratio: 0.29 and Accuracy: 0.5083333333333333\n",
            "Observation ratio: 0.3 and Accuracy: 0.5083333333333333\n",
            "Observation ratio: 0.31 and Accuracy: 0.5125\n",
            "Observation ratio: 0.32 and Accuracy: 0.5125\n",
            "Observation ratio: 0.33 and Accuracy: 0.525\n",
            "Observation ratio: 0.34 and Accuracy: 0.525\n",
            "Observation ratio: 0.35 and Accuracy: 0.5333333333333333\n",
            "Observation ratio: 0.36 and Accuracy: 0.55\n",
            "Observation ratio: 0.37 and Accuracy: 0.5541666666666667\n",
            "Observation ratio: 0.38 and Accuracy: 0.5625\n",
            "Observation ratio: 0.39 and Accuracy: 0.575\n",
            "Observation ratio: 0.4 and Accuracy: 0.5875\n",
            "Observation ratio: 0.41 and Accuracy: 0.5875\n",
            "Observation ratio: 0.42 and Accuracy: 0.6\n",
            "Observation ratio: 0.43 and Accuracy: 0.6125\n",
            "Observation ratio: 0.44 and Accuracy: 0.6166666666666667\n",
            "Observation ratio: 0.45 and Accuracy: 0.625\n",
            "Observation ratio: 0.46 and Accuracy: 0.6291666666666667\n",
            "Observation ratio: 0.47 and Accuracy: 0.6291666666666667\n",
            "Observation ratio: 0.48 and Accuracy: 0.6333333333333333\n",
            "Observation ratio: 0.49 and Accuracy: 0.6333333333333333\n",
            "Observation ratio: 0.5 and Accuracy: 0.6541666666666667\n",
            "Observation ratio: 0.51 and Accuracy: 0.6625\n",
            "Observation ratio: 0.52 and Accuracy: 0.6791666666666667\n",
            "Observation ratio: 0.53 and Accuracy: 0.6875\n",
            "Observation ratio: 0.54 and Accuracy: 0.7083333333333334\n",
            "Observation ratio: 0.55 and Accuracy: 0.7208333333333333\n",
            "Observation ratio: 0.56 and Accuracy: 0.725\n",
            "Observation ratio: 0.57 and Accuracy: 0.7291666666666666\n",
            "Observation ratio: 0.58 and Accuracy: 0.7291666666666666\n",
            "Observation ratio: 0.59 and Accuracy: 0.7291666666666666\n",
            "Observation ratio: 0.6 and Accuracy: 0.7333333333333333\n",
            "Observation ratio: 0.61 and Accuracy: 0.7375\n",
            "Observation ratio: 0.62 and Accuracy: 0.7375\n",
            "Observation ratio: 0.63 and Accuracy: 0.7416666666666667\n",
            "Observation ratio: 0.64 and Accuracy: 0.7458333333333333\n",
            "Observation ratio: 0.65 and Accuracy: 0.7458333333333333\n",
            "Observation ratio: 0.66 and Accuracy: 0.75\n",
            "Observation ratio: 0.67 and Accuracy: 0.75\n",
            "Observation ratio: 0.68 and Accuracy: 0.7541666666666667\n",
            "Observation ratio: 0.69 and Accuracy: 0.7583333333333333\n",
            "Observation ratio: 0.7 and Accuracy: 0.7583333333333333\n",
            "Observation ratio: 0.71 and Accuracy: 0.7583333333333333\n",
            "Observation ratio: 0.72 and Accuracy: 0.7583333333333333\n",
            "Observation ratio: 0.73 and Accuracy: 0.7625\n",
            "Observation ratio: 0.74 and Accuracy: 0.7625\n",
            "Observation ratio: 0.75 and Accuracy: 0.7625\n",
            "Observation ratio: 0.76 and Accuracy: 0.7625\n",
            "Observation ratio: 0.77 and Accuracy: 0.7666666666666667\n",
            "Observation ratio: 0.78 and Accuracy: 0.775\n",
            "Observation ratio: 0.79 and Accuracy: 0.7791666666666667\n",
            "Observation ratio: 0.8 and Accuracy: 0.7791666666666667\n",
            "Observation ratio: 0.81 and Accuracy: 0.7791666666666667\n",
            "Observation ratio: 0.82 and Accuracy: 0.7958333333333333\n",
            "Observation ratio: 0.83 and Accuracy: 0.7958333333333333\n",
            "Observation ratio: 0.84 and Accuracy: 0.7958333333333333\n",
            "Observation ratio: 0.85 and Accuracy: 0.8\n",
            "Observation ratio: 0.86 and Accuracy: 0.8041666666666667\n",
            "Observation ratio: 0.87 and Accuracy: 0.8083333333333333\n",
            "Observation ratio: 0.88 and Accuracy: 0.8208333333333333\n",
            "Observation ratio: 0.89 and Accuracy: 0.8208333333333333\n",
            "Observation ratio: 0.9 and Accuracy: 0.8208333333333333\n",
            "Observation ratio: 0.91 and Accuracy: 0.825\n",
            "Observation ratio: 0.92 and Accuracy: 0.825\n",
            "Observation ratio: 0.93 and Accuracy: 0.825\n",
            "Observation ratio: 0.94 and Accuracy: 0.8291666666666667\n",
            "Observation ratio: 0.95 and Accuracy: 0.8375\n",
            "Observation ratio: 0.96 and Accuracy: 0.825\n",
            "Observation ratio: 0.97 and Accuracy: 0.8333333333333334\n",
            "Observation ratio: 0.98 and Accuracy: 0.8333333333333334\n",
            "Observation ratio: 0.99 and Accuracy: 0.8166666666666667\n",
            "Observation ratio: 1.0 and Accuracy: 0.8166666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcYR7__up_RD",
        "colab_type": "text"
      },
      "source": [
        "Save the accuracy in a npy file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKhiBr8rVO2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/drive/My Drive/DLSTM_epoch_end_final.npy',accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2URFH61qHZy",
        "colab_type": "text"
      },
      "source": [
        "Load the accuracy array to plot it against the observation ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4ThEqLBOO-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "acc = np.load('/content/drive/My Drive/DLSTM_epoch_end_final.npy')\n",
        "ratios = np.arange(0.01,1.01,0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stixy6IxAeOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e206dc5a-b237-461c-e0b7-346a4e689c44"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(ratios,acc, label='LSTM')\n",
        "plt.grid(True)\n",
        "plt.xlabel('Avg Observation ratio')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('LSTM model')\n",
        "plt.xlim(0,1)\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}